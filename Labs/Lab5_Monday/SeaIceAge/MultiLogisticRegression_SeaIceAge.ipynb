{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression for Sea Ice Age\n",
    "\n",
    "Sea ice forms when saline ocean water freezes during cold winter months.  Note that sea ice is different than icebergs, which are chunks of freshwater glaciers that have broken off in to the ocean.\n",
    "\n",
    "Sea ice is commonly divided into multiple categories, such as first year ice and multiyear ice.  Multiyear ice is defined as ice that has survived at least one summer season.  Interestingly, multiyear ice often is often signficantly different that first year ice.  It is typically less saline, rougher, and thicker. \n",
    "\n",
    "In [1], satellite observations were used to estimate the age of ice across the Arctic basin from 1984 through 2016.  In this example, we will use their results to analyze the dependence of the January ice age on latitude, longitude, and time.\n",
    "\n",
    "Let $y(x,t)$ denote the observed age (from [1]) at a location $x$ and time $t$.  The value of $y(x,t)$ can be one of three things:\n",
    "\n",
    "$$\n",
    "y(x,t) \\in \\{0,1,2\\} = \\{\\text{No Ice},\\,\\, \\text{First Year},\\,\\, \\text{Multiyear} \\}\n",
    "$$\n",
    "\n",
    "Now recall the components of a Bayesian inference problem:\n",
    "1. The likelihood function, which is a statistical model describing the data\n",
    "2. The prior distribution, which describes any prior information we have about the parameters\n",
    "\n",
    "### Likelihood function\n",
    "At each point in space and time, the probability of the ice being in state $i$ is given by\n",
    "\n",
    "$$\n",
    "P_i(x,t) = \\mathbb{P}[\\,y(x,t)=i\\,]\n",
    "$$\n",
    "\n",
    "for $i\\in \\{0,1,2\\}$.  Our statistical model for the data will model these probabilities using polynomial expansions. In particular, consider the new predictor variable $s_{i}(x,t;m)$ that takes the form\n",
    "\n",
    "$$\n",
    "s_{i}(x,t; m) = \\exp\\left[\\sum_{j=1}^P m_{i,j} \\Phi(x,t)\\right]\n",
    "$$\n",
    "\n",
    "Normalizing the predictor variables allows us to model the probabilities:\n",
    "\n",
    "$$\n",
    "P_i(x,t; m) = \\frac{s_{i}(x,t; m)}{\\sum_{n=1}^3 s_{n}(x,t; m)}\n",
    "$$\n",
    "\n",
    "Assume we have $N$ independent observations $\\{y_1,\\ldots, y_N\\}$ at locations $\\{x_1,\\ldots, x_N\\}$ and times $\\{t_1,\\ldots, t_N\\}$.  Under this assumption, the likelihood function takes the form \n",
    "\n",
    "$$\n",
    "p(y | m) = \\prod_{k=1}^N P_{y_k}(x_k, t_k; m) = \\frac{s_{y_k}(x_k, t_k; m)}{\\sum_{n=1}^3 s_{n}(x_k, t_k; m)}\n",
    "$$\n",
    "\n",
    "This approach of modeling the probabilities is commonly called multinomial logistic regression.  **The parameters we want to infer are the polynomial coefficients $m$.**\n",
    "\n",
    "### Prior distribution\n",
    "\n",
    "\n",
    "$$\n",
    "m \\sim N(0, I)\n",
    "$$\n",
    "\n",
    "\n",
    "### References\n",
    "[1] Tschudi, M., C. Fowler, J. Maslanik, J. S. Stewart, and W. Meier. 2016. EASE-Grid Sea Ice Age, Version 3. Boulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center. doi: https://doi.org/10.5067/PFSVFZA9Y85G. [06/14/2018].\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/home/fenics/Installations/MUQ_INSTALL/lib')\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Helper functions pre-written for this problem\n",
    "from IceAgeUtilities import *\n",
    "from PlotUtilities import *\n",
    "\n",
    "# MUQ Includes\n",
    "import pymuqModeling as mm\n",
    "import pymuqApproximation as ma\n",
    "import pymuqUtilities as mu\n",
    "import pymuqSamplingAlgorithms as ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n",
    "\n",
    "\n",
    "### Scaling for efficiency\n",
    "In the original data, the observation locations are specified in terms of the latitude $x_{lat}$ and longitude $x_{lon}$.  However, the polynomial expansions used below are more numerically robust when the locations are scaled into $[0,1]$.  Moreover, the longitudes are periodic, so $s_i(x,t; m) = s_k(x+2\\pi,t; m)$.  To rescale the positions, we therefore define $x$ as \n",
    "\n",
    "$$\n",
    "x = \\left[ \\begin{array}{c} x_1, x_2 \\end{array}\\right] = \\left[ \\begin{array}{c} \\frac{x_{lat} - \\min(x_{lat})}{\\max(x_{lat}) - \\min(x_{lat})}\\\\ \\frac{1}{2}\\cos\\left(2\\pi \\frac{x_{lon} - \\min(x_{lon})}{\\max(x_{lon}) - \\min(x_{lon})}\\right)+\\frac{1}{2}  \\end{array}\\right].\n",
    "$$\n",
    "\n",
    "The time is scaled similarly\n",
    "\n",
    "$$\n",
    "t = \\frac{t - \\min(t)}{\\max(t)-\\min(t)}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thinBy = 150\n",
    "numClasses = 3 \n",
    "\n",
    "timeRaw, latRaw, lonRaw, ages = ReadIceAges(thinBy, numClasses)\n",
    "\n",
    "# Scale the independent variables to have domain [0,1]\n",
    "minTime, maxTime = np.min(timeRaw), np.max(timeRaw)\n",
    "minLat, maxLat = np.min(latRaw), np.max(latRaw)\n",
    "minLon, maxLon = np.min(lonRaw), np.max(lonRaw)\n",
    "\n",
    "time = (timeRaw-minTime)/(maxTime-minTime)\n",
    "lat = (latRaw-minLat)/(maxLat-minLat)\n",
    "lon = 0.5*np.cos( 2.0*np.pi*(lonRaw-minLon)/(maxLon - minLon) )+0.5\n",
    "\n",
    "numObs = len(ages)\n",
    "print('Using a total of %d age observations'%numObs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,20))\n",
    "\n",
    "ax = fig.add_subplot(131)\n",
    "PlotAgeScatter(1984, timeRaw, latRaw, lonRaw, ages)\n",
    "\n",
    "ax = fig.add_subplot(132)\n",
    "PlotAgeScatter(2000, timeRaw, latRaw, lonRaw, ages)\n",
    "\n",
    "ax = fig.add_subplot(133)\n",
    "PlotAgeScatter(2016, timeRaw, latRaw, lonRaw, ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Multi-Logistic Regression\n",
    "We assume that each predictor variable $s_i(x,t; m)$ is modeled with the same polynomial basis functions, resulting in \n",
    "\n",
    "$$\n",
    "s_i(x,t;m) = \\sum_{j=1}^P m_{i,j}\\Phi_j(x,t)\n",
    "$$\n",
    "\n",
    "We collect all of the predictor variables into a single vector $s$ given by\n",
    "$$\n",
    "s = \\left[\\begin{array}{c} s_1(x_1, t_1; m)\\\\ s_2(x_1, t_1; m) \\\\ s_3(x_1, t_1; m) \\\\ s_1(x_2, t_2; m) \\\\ \\vdots \\\\ s_1(x_N, t_N; m)\\\\ s_2(x_N, t_N; m) \\\\ s_3(x_N, t_N; m) \\end{array}\\right].\n",
    "$$\n",
    "\n",
    "The predictor variables can be related to the model parameters $m$ with a Vandermonde matrix $V$\n",
    "\n",
    "$$\n",
    "s = Vm,\n",
    "$$\n",
    "\n",
    "where the Vandermonde matrix is given by\n",
    "\n",
    "$$\n",
    "V = \\left[\n",
    "\\begin{array}{ccccccccc}\n",
    "\\Phi_1(x_1,t_1) & \\cdots & \\Phi_P(x_1,t_1) & 0 & \\cdots & 0 & 0 & \\cdots & 0\\\\\n",
    "0 & \\cdots & 0 &\\Phi_1(x_1,t_1) & \\cdots & \\Phi_P(x_1,t_1) &  0 & \\cdots & 0\\\\\n",
    "0 & \\cdots & 0 &0 & \\cdots & 0 & \\Phi_1(x_1,t_1) & \\cdots & \\Phi_P(x_1,t_1) \\\\\n",
    "\\Phi_1(x_2,t_2) & \\cdots & \\Phi_P(x_2,t_2) & 0 & \\cdots & 0 & 0 & \\cdots & 0\\\\\n",
    "0 & \\cdots & 0 &\\Phi_1(x_2,t_2) & \\cdots & \\Phi_P(x_2,t_2) &  0 & \\cdots & 0\\\\\n",
    "0 & \\cdots & 0 &0 & \\cdots & 0 & \\Phi_1(x_2,t_2) & \\cdots & \\Phi_P(x_2,t_2) \\\\\n",
    "\\vdots & &\\vdots & \\vdots & &\\vdots &\\vdots & & \\vdots \\\\\n",
    "\\Phi_1(x_N,t_1) & \\cdots & \\Phi_P(x_N,t_1) & 0 & \\cdots & 0 & 0 & \\cdots & 0\\\\\n",
    "0 & \\cdots & 0 &\\Phi_1(x_N,t_1) & \\cdots & \\Phi_P(x_N,t_1) &  0 & \\cdots & 0\\\\\n",
    "0 & \\cdots & 0 &0 & \\cdots & 0 & \\Phi_1(x_N,t_N) & \\cdots & \\Phi_P(x_N,t_N)\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Because we have more than one output variable, this matrix is slightly different than the typical Vandermonde matrix used in linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyOrder = 2 # Maximum total order of the polynomial basis\n",
    "numIndp = 3   # number of independent variables [time, lat, lon]\n",
    "\n",
    "# Generate the set of total order limited multiindices\n",
    "multiSet  = mu.MultiIndexFactory.CreateTotalOrder(numIndp,polyOrder)\n",
    "\n",
    "# What type of polynomials do we want to use?  ProbabilistHermite\n",
    "poly = ma.ProbabilistHermite()\n",
    "\n",
    "# Construct the Vandermonde matrix for one class\n",
    "partialV = ma.BasisExpansion([poly]*numIndp, multiSet).BuildVandermonde(np.hstack([time[:,None], lat[:,None], lon[:,None]]).T )\n",
    "\n",
    "termsPerClass = partialV.shape[1]\n",
    "\n",
    "# Construct the complete Vandermonde matrix by \"stamping\" the one-class Vandermonde matrix into V\n",
    "V = np.zeros((numClasses*numObs, numClasses*termsPerClass))\n",
    "for c in range(numClasses):\n",
    "    V[c::numClasses, c*termsPerClass:(c+1)*termsPerClass] = partialV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forwardModel = mm.DenseLinearOperator(V)\n",
    "print('Number of model parameters = ', forwardModel.inputSizes[0])\n",
    "\n",
    "likelihood = mm.MultiLogisticLikelihood(numClasses,ages)\n",
    "\n",
    "prior = mm.Gaussian(np.zeros(V.shape[1]), 100*np.eye(V.shape[1])).AsDensity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the posterior density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = mm.WorkGraph()\n",
    "\n",
    "graph.AddNode(mm.IdentityOperator(V.shape[1]),\"Parameters\")\n",
    "graph.AddNode(mm.DensityProduct(2), \"Posterior\")\n",
    "\n",
    "# TODO: Define the posterior density using a WorkGraph\n",
    "#  - Add nodes for the forward model and likelihood\n",
    "#  - Add appropriate edges to build the posteror \"diamond\"\n",
    "\n",
    "graph.AddNode(prior,\"Prior\")\n",
    "graph.AddNode(forwardModel, \"ForwardModel\")\n",
    "graph.AddNode(likelihood, \"Likelihood\")\n",
    "\n",
    "\n",
    "graph.AddEdge(\"Parameters\",0, \"Prior\",0)\n",
    "graph.AddEdge(\"Parameters\",0,\"ForwardModel\",0)\n",
    "graph.AddEdge(\"ForwardModel\",0, \"Likelihood\",0)\n",
    "graph.AddEdge(\"Likelihood\",0, \"Posterior\",1)\n",
    "graph.AddEdge(\"Prior\",0, \"Posterior\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.Visualize(\"PosteriorGraph.png\")\n",
    "Image(filename='PosteriorGraph.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the posterior with MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = ms.SamplingProblem(graph.CreateModPiece(\"Posterior\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposalOptions = dict()\n",
    "proposalOptions['Method'] = 'AMProposal'\n",
    "proposalOptions['ProposalVariance'] = 1e-3\n",
    "proposalOptions['AdaptSteps'] = 100\n",
    "proposalOptions['AdaptStart'] = 1000\n",
    "proposalOptions['AdaptScale'] = 5e-2\n",
    "\n",
    "kernelOptions = dict()\n",
    "kernelOptions['Method'] = 'MHKernel'\n",
    "kernelOptions['Proposal'] = 'ProposalBlock'\n",
    "kernelOptions['ProposalBlock'] = proposalOptions\n",
    "\n",
    "options = dict()\n",
    "options['NumSamples'] = 100000\n",
    "options['KernelList'] = 'Kernel1'\n",
    "options['PrintLevel'] = 3\n",
    "options['Kernel1'] = kernelOptions\n",
    "\n",
    "mcmc = ms.SingleChainMCMC(options,problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startPt = np.zeros(V.shape[1])\n",
    "samps = mcmc.Run(startPt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generated a chain of length %d'%samps.size())\n",
    "sampMat = samps.AsMatrix()\n",
    "\n",
    "plt.plot(sampMat.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample the Posterior Predictive Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a single random posterior-predictive sample\n",
    "burnIn = 50000\n",
    "mcmcInd = np.random.randint(burnIn,options['NumSamples'],1)[0]\n",
    "\n",
    "logProbs = forwardModel.Evaluate([sampMat[:,mcmcInd]])[0].reshape(-1,numClasses).T\n",
    "NormalizeProbs(logProbs)\n",
    "    \n",
    "ageSamp = np.zeros(numObs)\n",
    "for i in range(numObs):\n",
    "    ageSamp[i] = np.random.choice(list(range(numClasses)), 1, p=np.exp(logProbs[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,20))\n",
    "\n",
    "ax = fig.add_subplot(131)\n",
    "PlotAgeScatter(1984, timeRaw, latRaw, lonRaw, ageSamp)\n",
    "\n",
    "ax = fig.add_subplot(132)\n",
    "PlotAgeScatter(2000, timeRaw, latRaw, lonRaw, ageSamp)\n",
    "\n",
    "ax = fig.add_subplot(133)\n",
    "PlotAgeScatter(2016, timeRaw, latRaw, lonRaw, ageSamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study the Probability Over Time\n",
    "\n",
    "Using the posterior samples, we can now investigate the posterior predictive distribution and answer questions like:\n",
    "- What is the probability of seeing multiyear ice in the future?\n",
    "- Looking to the future, how likely is it to see any sea ice?\n",
    "\n",
    "To illustrate how to use the posterior predictive, we will focus on a single location: latitude 76, longitude 28, and years from 1984 to 2041.\n",
    "\n",
    "<img src=\"PointOfInterest.png\" alt=\"POI\" width=\"600px\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the new latitude, longitudes, and times where we want to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newTimeRaw = np.array(range(1984,2041))\n",
    "newLatRaw = 76 * np.ones(newTimeRaw.shape[0])\n",
    "newLonRaw = 28 * np.ones(newTimeRaw.shape[0])\n",
    "\n",
    "# Scale the independent variables in the same way we did above\n",
    "newTime = (newTimeRaw - minTime)/(maxTime-minTime)\n",
    "newLat = (newLatRaw - minLat)/(maxLat-minLat)\n",
    "newLon = 0.5 * np.cos( 2.0*np.pi * (newLonRaw-minLon)/(maxLon-minLon))+0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct the forward model for the predictor variables\n",
    "$$\n",
    "s_i(x,t;m) = \\sum_{j=1}^P m_{i,j}\\Phi_j(x,t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the Vandermonde matrix for the new points\n",
    "partialV = ma.BasisExpansion([poly]*numIndp, multiSet).BuildVandermonde(np.hstack([newTime[:,None], newLat[:,None], newLon[:,None]]).T )\n",
    "V = np.zeros((numClasses*newTimeRaw.shape[0], numClasses*termsPerClass))\n",
    "for c in range(numClasses):\n",
    "    V[c::numClasses, c*termsPerClass:(c+1)*termsPerClass] = partialV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the class probabilities\n",
    "$$\n",
    "P_i(x,t; m) = \\frac{s_{i}(x,t; m)}{\\sum_{n=1}^3 s_{n}(x,t; m)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the marginal log-probabilities (integrating over model parameters)\n",
    "probs = np.zeros((numClasses, newTimeRaw.shape[0], options['NumSamples']-burnIn ))\n",
    "for i in range(burnIn,options['NumSamples']):\n",
    "    currProb = np.exp(np.dot(V, sampMat[:,i]).reshape(-1,numClasses).T)\n",
    "    currProb /= np.sum(currProb,axis=0)\n",
    "    probs[:,:,i-burnIn] = currProb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the probability of multiyear ice being present\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(15,5))\n",
    "\n",
    "axs[0].fill_between(newTimeRaw,np.percentile(probs[2,:,:],1,axis=1),np.percentile(probs[2,:,:],99,axis=1), alpha=0.4, edgecolor='None', label='1% to 99% CI')\n",
    "axs[0].plot(newTimeRaw, np.mean(probs[2,:,:],axis=1), 'k', linewidth=3, label='Mean')\n",
    "\n",
    "axs[0].set_title('Probability of Multiyear Ice During Jan. 1-7 ($%0.0f^\\circ N$, $%0.0f^\\circ E$)'%(newLatRaw[0], newLonRaw[0]))\n",
    "axs[0].set_xlabel('Year')\n",
    "axs[0].set_ylabel('Probability of Occurence')\n",
    "axs[0].set_ylim([0,0.2])\n",
    "axs[0].set_xlim([1984,2040])\n",
    "axs[0].legend()\n",
    "\n",
    "## Plot the probability of any ice being present\n",
    "axs[1].fill_between(newTimeRaw,np.percentile(1-probs[0,:,:],1,axis=1),np.percentile(1-probs[0,:,:],99,axis=1), alpha=0.4, edgecolor='None', label='1% to 99% CI') \n",
    "axs[1].plot(newTimeRaw, np.mean(1.0-probs[0,:,:],axis=1), 'k', linewidth=3, label='Mean')\n",
    "\n",
    "axs[1].set_title('Probability of Any Ice During Jan. 1-7 ($%0.0f^\\circ N$, $%0.0f^\\circ E$)'%(newLatRaw[0], newLonRaw[0]))\n",
    "axs[1].set_xlabel('Year')\n",
    "axs[1].set_ylabel('Probability of Occurence')\n",
    "axs[1].set_ylim([0,0.6])\n",
    "axs[1].set_xlim([1984,2040])\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
